{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb995c5-ef85-48ea-8395-9e2099835542",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c971b-8560-464d-b281-5612db20d7ab",
   "metadata": {},
   "source": [
    "  1. Connect to your PostgreSQL DB.\n",
    "  2. Fetch existing order data (either from staging.orders or dw.fact_orders).\n",
    "  3. Generate a small set of synthetic warehouse data.\n",
    "  4. Generate synthetic shipment records (one or more shipments per order) \n",
    "     with random carriers, dates, and costs.\n",
    "  5. Insert results into staging.synthetic_warehouse and staging.synthetic_shipments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc27905-b0ab-4865-be90-a7b132c0cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d4f5a-365b-4a6a-8055-b2a515f288dc",
   "metadata": {},
   "source": [
    "# Method 1: Direct DB Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95e281e2-cb7a-48f6-8bb4-2ea840805441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 5 warehouses and 20000 synthetic shipments into staging.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "generate_synthetic_shipment_data.py\n",
    "\n",
    "Purpose:\n",
    "  1. Connect to your PostgreSQL DB.\n",
    "  2. Fetch existing order data (either from staging.orders or dw.fact_orders).\n",
    "  3. Generate a small set of synthetic warehouse data.\n",
    "  4. Generate synthetic shipment records (one or more shipments per order) \n",
    "     with random carriers, dates, and costs.\n",
    "  5. Insert results into staging.synthetic_warehouse and staging.synthetic_shipments.\n",
    "\n",
    "Usage:\n",
    "  python generate_synthetic_shipment_data.py\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "DB_HOST = \"localhost\"\n",
    "DB_NAME = \"ecommerce_warehouse\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"YourPasswordHere\"\n",
    "DB_PORT = 5432\n",
    "\n",
    "NUM_WAREHOUSES = 5  # How many synthetic warehouses to generate\n",
    "CARRIERS = [\"Correios\", \"Loggi\", \"Stark Logistics\", \"Dragonfly Express\", \"RapidAir\"]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# -----------------------------------------------------------------------------\n",
    "def random_date(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Return a random datetime between two datetime objects.\n",
    "    \"\"\"\n",
    "    delta = end_date - start_date\n",
    "    rand_seconds = random.randrange(int(delta.total_seconds()))\n",
    "    return start_date + datetime.timedelta(seconds=rand_seconds)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Main Logic\n",
    "# -----------------------------------------------------------------------------\n",
    "def main():\n",
    "    # 1. Connect to Postgres\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    conn.autocommit = True  # So each statement commits automatically\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # 2. (Optional) Create staging tables for synthetic data if not exist\n",
    "    #    staging.synthetic_warehouse, staging.synthetic_shipments\n",
    "    create_staging_sql = \"\"\"\n",
    "    CREATE SCHEMA IF NOT EXISTS staging;\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS staging.synthetic_warehouse (\n",
    "        synthetic_warehouse_id SERIAL PRIMARY KEY,\n",
    "        warehouse_name TEXT,\n",
    "        warehouse_location TEXT,\n",
    "        capacity INT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS staging.synthetic_shipments (\n",
    "        synthetic_shipment_id SERIAL PRIMARY KEY,\n",
    "        order_id TEXT,\n",
    "        warehouse_id INT,   -- will map to synthetic_warehouse_id\n",
    "        carrier TEXT,\n",
    "        ship_date TIMESTAMP,\n",
    "        delivery_date TIMESTAMP,\n",
    "        shipping_cost NUMERIC(10,2)\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_staging_sql)\n",
    "\n",
    "    # 3. Generate a small set of random warehouses\n",
    "    warehouse_data = []\n",
    "    for i in range(NUM_WAREHOUSES):\n",
    "        warehouse_name = f\"Warehouse_{i+1}\"\n",
    "        # random city + state combos (just examples)\n",
    "        possible_locations = [\n",
    "            \"Sao Paulo - SP\", \"Rio de Janeiro - RJ\", \"Belo Horizonte - MG\",\n",
    "            \"Salvador - BA\", \"Porto Alegre - RS\"\n",
    "        ]\n",
    "        warehouse_location = random.choice(possible_locations)\n",
    "        capacity = random.randint(5000, 20000)  # random capacity\n",
    "        warehouse_data.append((warehouse_name, warehouse_location, capacity))\n",
    "\n",
    "    insert_warehouse_sql = \"\"\"\n",
    "        INSERT INTO staging.synthetic_warehouse \n",
    "        (warehouse_name, warehouse_location, capacity)\n",
    "        VALUES (%s, %s, %s)\n",
    "    \"\"\"\n",
    "    execute_batch(cursor, insert_warehouse_sql, warehouse_data)\n",
    "\n",
    "    # 4. Fetch existing orders to create shipments\n",
    "    #    You can pull from staging.orders OR from dw.fact_orders depending on your pipeline\n",
    "    fetch_orders_sql = \"\"\"\n",
    "        SELECT order_id, order_purchase_timestamp\n",
    "        FROM staging.orders\n",
    "        WHERE order_purchase_timestamp IS NOT NULL\n",
    "        LIMIT 20000  -- example limit if you don't want all\n",
    "    \"\"\"\n",
    "    cursor.execute(fetch_orders_sql)\n",
    "    orders = cursor.fetchall()  # list of tuples: (order_id, order_purchase_timestamp)\n",
    "\n",
    "    # 5. Map each existing order to a random warehouse + random ship/delivery\n",
    "    #    We'll assume shipping always after purchase_date\n",
    "    #    We'll generate 1 shipment per order for simplicity. \n",
    "    #    If you want multiple shipments per order, you can do so.\n",
    "    shipment_data = []\n",
    "    for (order_id, purchase_ts) in orders:\n",
    "        # pick a random warehouse from the newly inserted ones\n",
    "        warehouse_id = random.randint(1, NUM_WAREHOUSES)  # because synthetic_warehouse_id is 1..N\n",
    "        carrier = random.choice(CARRIERS)\n",
    "\n",
    "        # random ship_date: between purchase_ts + 0 hours and purchase_ts + 3 days\n",
    "        earliest_ship = purchase_ts\n",
    "        latest_ship = purchase_ts + datetime.timedelta(days=3)\n",
    "        # but ensure earliest_ship < latest_ship in case times are borderline\n",
    "        if earliest_ship > latest_ship:\n",
    "            # swap them if something is off (rare corner case)\n",
    "            earliest_ship, latest_ship = latest_ship, earliest_ship\n",
    "        \n",
    "        ship_date = random_date(earliest_ship, latest_ship)\n",
    "\n",
    "        # random delivery_date: between ship_date and ship_date + 7 days\n",
    "        earliest_delivery = ship_date\n",
    "        latest_delivery = ship_date + datetime.timedelta(days=7)\n",
    "        delivery_date = random_date(earliest_delivery, latest_delivery)\n",
    "\n",
    "        shipping_cost = round(random.uniform(5.0, 50.0), 2)  # random cost\n",
    "\n",
    "        shipment_data.append((\n",
    "            order_id,\n",
    "            warehouse_id,\n",
    "            carrier,\n",
    "            ship_date,\n",
    "            delivery_date,\n",
    "            shipping_cost\n",
    "        ))\n",
    "\n",
    "    insert_shipments_sql = \"\"\"\n",
    "        INSERT INTO staging.synthetic_shipments\n",
    "        (order_id, warehouse_id, carrier, ship_date, delivery_date, shipping_cost)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    execute_batch(cursor, insert_shipments_sql, shipment_data, page_size=1000)\n",
    "\n",
    "    # 6. Clean up\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Inserted {len(warehouse_data)} warehouses and {len(shipment_data)} synthetic shipments into staging.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682fc27a-290d-475a-aba6-157028295540",
   "metadata": {},
   "source": [
    "# Method 2: .CSV Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1564598-a3d6-445e-9305-707f2995f34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 20000 orders from staging.orders.\n",
      "Created synthetic_warehouses.csv with 5 rows.\n",
      "Created synthetic_shipments.csv with 20000 rows.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "generate_synthetic_shipment_data_csv.py\n",
    "\n",
    "Purpose:\n",
    "  1. Connects to PostgreSQL to fetch existing order data (order_id, order_purchase_timestamp).\n",
    "  2. Generates a small set of synthetic warehouse data in a DataFrame.\n",
    "  3. Creates synthetic shipment records (1 shipment per order) with random carriers, dates, costs.\n",
    "  4. Writes the results to:\n",
    "       - synthetic_warehouses.csv\n",
    "       - synthetic_shipments.csv\n",
    "  No direct DB insertion—use CSV + COPY from staging approach.\n",
    "\n",
    "Usage:\n",
    "  python generate_synthetic_shipment_data_csv.py\n",
    "\n",
    "After that, from psql or your SQL script, do:\n",
    "  COPY staging.synthetic_warehouse \n",
    "      FROM '/path/to/synthetic_warehouses.csv' CSV HEADER;\n",
    "\n",
    "  COPY staging.synthetic_shipments \n",
    "      FROM '/path/to/synthetic_shipments.csv' CSV HEADER;\n",
    "\"\"\"\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Configurations\n",
    "# -----------------------------------------------------------------------------\n",
    "DB_HOST = \"localhost\"\n",
    "DB_NAME = \"ecommerce_warehouse\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"YourPasswordHere\"\n",
    "DB_PORT = 5432\n",
    "\n",
    "NUM_WAREHOUSES = 5\n",
    "CARRIERS = [\"Correios\", \"Loggi\", \"Stark Logistics\", \"Dragonfly Express\", \"RapidAir\"]\n",
    "\n",
    "OUTPUT_WAREHOUSES_CSV = \"synthetic_warehouses.csv\"\n",
    "OUTPUT_SHIPMENTS_CSV = \"synthetic_shipments.csv\"\n",
    "\n",
    "# Random date helpers\n",
    "def random_date(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Return a random datetime between two datetime objects.\n",
    "    \"\"\"\n",
    "    delta = end_date - start_date\n",
    "    rand_seconds = random.randrange(int(delta.total_seconds()))\n",
    "    return start_date + datetime.timedelta(seconds=rand_seconds)\n",
    "\n",
    "def main():\n",
    "    # 1. Connect to Postgres to fetch orders\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # For example, pull from staging.orders\n",
    "    fetch_orders_sql = \"\"\"\n",
    "        SELECT order_id, order_purchase_timestamp\n",
    "        FROM staging.orders\n",
    "        WHERE order_purchase_timestamp IS NOT NULL\n",
    "        LIMIT 20000;  -- adjust limit as desired\n",
    "    \"\"\"\n",
    "    cursor.execute(fetch_orders_sql)\n",
    "    orders = cursor.fetchall()  # list of tuples: (order_id, order_purchase_timestamp)\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Fetched {len(orders)} orders from staging.orders.\")\n",
    "\n",
    "    # 2. Generate synthetic warehouse data\n",
    "    warehouse_list = []\n",
    "    possible_locations = [\n",
    "        \"Sao Paulo - SP\",\n",
    "        \"Rio de Janeiro - RJ\",\n",
    "        \"Belo Horizonte - MG\",\n",
    "        \"Salvador - BA\",\n",
    "        \"Porto Alegre - RS\"\n",
    "    ]\n",
    "    for i in range(1, NUM_WAREHOUSES + 1):\n",
    "        warehouse_name = f\"Warehouse_{i}\"\n",
    "        warehouse_location = random.choice(possible_locations)\n",
    "        capacity = random.randint(5000, 20000)\n",
    "        warehouse_list.append({\n",
    "            \"synthetic_warehouse_id\": i,  # We'll use 1..N as ID\n",
    "            \"warehouse_name\": warehouse_name,\n",
    "            \"warehouse_location\": warehouse_location,\n",
    "            \"capacity\": capacity\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame for easy CSV output\n",
    "    df_warehouses = pd.DataFrame(warehouse_list)\n",
    "\n",
    "    # 3. Create shipments for each order (1:1)\n",
    "    #    If you want multiple shipments per order, you can create more rows per order.\n",
    "    shipment_rows = []\n",
    "    for (order_id, purchase_ts) in orders:\n",
    "        warehouse_id = random.randint(1, NUM_WAREHOUSES)  # random assignment\n",
    "        carrier = random.choice(CARRIERS)\n",
    "\n",
    "        earliest_ship = purchase_ts\n",
    "        latest_ship = purchase_ts + datetime.timedelta(days=3)\n",
    "        if earliest_ship > latest_ship:  # rare case if timestamp is weird\n",
    "            earliest_ship, latest_ship = latest_ship, earliest_ship\n",
    "        ship_date = random_date(earliest_ship, latest_ship)\n",
    "\n",
    "        earliest_delivery = ship_date\n",
    "        latest_delivery = ship_date + datetime.timedelta(days=7)\n",
    "        delivery_date = random_date(earliest_delivery, latest_delivery)\n",
    "\n",
    "        shipping_cost = round(random.uniform(5.0, 50.0), 2)\n",
    "\n",
    "        shipment_rows.append({\n",
    "            \"synthetic_shipment_id\": None,  # We'll let DB assign if we want\n",
    "            \"order_id\": order_id,\n",
    "            \"warehouse_id\": warehouse_id,  # references synthetic_warehouse_id\n",
    "            \"carrier\": carrier,\n",
    "            \"ship_date\": ship_date,\n",
    "            \"delivery_date\": delivery_date,\n",
    "            \"shipping_cost\": shipping_cost\n",
    "        })\n",
    "\n",
    "    df_shipments = pd.DataFrame(shipment_rows)\n",
    "\n",
    "    # 4. Write out to CSV\n",
    "    df_warehouses.to_csv(OUTPUT_WAREHOUSES_CSV, index=False)\n",
    "    df_shipments.to_csv(OUTPUT_SHIPMENTS_CSV, index=False)\n",
    "\n",
    "    print(f\"Created {OUTPUT_WAREHOUSES_CSV} with {len(df_warehouses)} rows.\")\n",
    "    print(f\"Created {OUTPUT_SHIPMENTS_CSV} with {len(df_shipments)} rows.\")\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
